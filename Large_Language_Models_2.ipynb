{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX255moWb3r8",
        "outputId": "dfb30955-8d7c-441a-bfe0-e0f88fd0d6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit transformers --quiet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ngrok config add-authtoken 2zK2X513eJPKy4rQhHdYUx21aIY_sHdVn4GhRSK6Ziyv57Kh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCe7uoJ4fwZL",
        "outputId": "4e0c0781-49a8-46b4-8b65-57b010355767"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "import streamlit as st\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Configuration\n",
        "st.set_page_config(page_title=\"LLM Chatbot\", page_icon=\"🤖\")\n",
        "st.title(\"🤖 LLM Chatbot - Streamlit\")\n",
        "\n",
        "# Charger le modèle LLM\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model_name = \"google/flan-t5-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    return pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "chatbot = load_model()\n",
        "\n",
        "# Initialiser l'historique\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Afficher l'historique\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "# Entrée utilisateur\n",
        "if prompt := st.chat_input(\"Pose une question au chatbot...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        response = chatbot(f\"Answer as a helpful chatbot: {prompt}\", max_new_tokens=100)[0]['generated_text']\n",
        "        st.markdown(response)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "'''\n",
        "\n",
        "with open(\"chatbot_app.py\", \"w\") as f:\n",
        "    f.write(code)\n"
      ],
      "metadata": {
        "id": "5KxaWPtUcsNR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIXIU0R1fvkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Ouvrir un tunnel sur le port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"🌐 Votre app Streamlit est disponible ici : {public_url}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XPdwIK6dltF",
        "outputId": "53b09452-6e6e-47a5-970e-5963e95520e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Votre app Streamlit est disponible ici : NgrokTunnel: \"https://ce90-34-80-206-74.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run chatbot_app.py &> /dev/null &\n"
      ],
      "metadata": {
        "id": "hCVYygFzf5cO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KZGqzfwf8Ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}